# BracketCloser-LLM-a 改修レポート

## 問題点
- 学習と評価の目的不一致：学習は「接頭辞→次トークン」の1トークン分類だが、評価は可変長生成を要求しており、特に k≥2 で精度が頭打ちになっていた。
- 語彙設計のノイズ：`input`, `,output`, `,` など入出力混在の9語彙を持ち、出力側で不要なトークンを学習していた。
- デコード無制約：評価時の貪欲生成でスタック整合や EOS 条件が弱く、誤トークン選択・早期終了が頻発した。
- マスク不整合：推論時の attention_mask がトークン ID のままで、学習時のバイナリマスクと挙動がずれていた。

## 修正内容
- 目的の統一（自己回帰 LM 化）：入力の全系列を右シフトしたラベルで学習し、時系列出力（TimeDistributed）に変更。GRU/LSTM/Transformer/BERT/GPT すべてを返却系列化。
- 語彙と前処理の整理：語彙を `[BOS]`, `[SEP]`, `[EOS]` と括弧のみに再定義し、データを `[BOS] input [SEP] output [EOS]` で保存・学習・評価するよう統一。
- デコードの安定化：評価時にスタック制約マスクを導入し、スタックが空になるまで EOS を禁止。モデル出力は時系列ロジットの最新ステップを使用。
- マスクの整合：推論時の attention_mask を (token!=0) のバイナリに統一し、学習時と合わせた。

## 直ったポイント
- 学習と評価が同じ可変長生成タスクになったため、出力長が2以上でも全ステップに損失がかかるようになった。
- 出力語彙が「閉じ括弧＋EOS」に近い形へ整理され、不要トークンによるノイズが除去。
- スタック整合と EOS 制約により、途中で別トークンや早期 EOS を選ぶケースが抑制。
- attention_mask の挙動が学習・推論で一致し、長め入力でも安定化。

## 残課題・注意
- 旧フォーマット（input/,output/, カンマEOS）前提のスクリプト（例: evaluate2.py）は未対応のため、新フォーマットで評価する際は modules/evaluate.py を使用すること。
- 旧モデル・旧データとの互換性はないため、新語彙・新前処理でデータを再生成して再学習する必要がある。

## 再現確認（推奨手順）
1. 新フォーマットでデータ生成を実行（train.py で学習時に自動生成されます）。
2. train.py で学習を実行（新モデルを保存）。
3. modules/evaluate.py で評価し、k≥2 正答率が改善していることを確認。
